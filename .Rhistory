####################
# total number of patients
nrow(prostate)
# number alive and dead
prostate %>% count(status)
sum(prostate$status != 'alive', na.rm=TRUE)
# is there missing values?????
tibble(prostate) %>%
filter(if_any(everything(), is.na)) # 27 rows with missing data
w = transcan(~ sz + sg + ap + sbp + dbp + age + wt + hg + ekg + pf + bm + hx,
imputed = TRUE, trantab=TRUE, data = prostate, pl = FALSE, pr = FALSE)
summary(w)
attach(prostate)
sz = impute(w, sz, data = prostate)
sg = impute(w, sg, data = prostate)
age = impute(w, age, data = prostate)
wt = impute(w, wt, data = prostate)
ekg = impute(w, ekg, data = prostate)
sg
dd = datadist(prostate); options(datadist = 'dd')
dd = datadist(prostate); options(datadist = 'dd')
dd
ggplot(w,scale=TRUE)+theme(axis.text.x=element_text(size=6))
# create survival object based of time of death
S = Surv(dtime, status != 'alive')
# perform a cox proportional hazard model on all variables, use restricted cubic
# spline for certain variables
#
f = cph(S ~ rx + rcs(age, 4) + rcs(wt, 4) + pf + hx + rcs(sbp, 4) + rcs(dbp, 4) +
ekg + rcs(hg, 4) + rcs(sg, 4) + rcs(sz, 4) + rcs(log(ap), 4) + bm)
print(f, latex = TRUE, coefs = FALSE)
# 3) would the next step be to investigate which variables are significant in
#   this model and remove those which are not accordingly?
##* you could issue this command to see the strength of association of each predictor
##* and whether nonlinearities are warranted. Overall, there is evidence of nonlinearities
##* of some predictors, and also no evidence of association for some others (e.g. sbp, sg)
anova(f)
anova(f2)
heart = hx + ekg %nin% c('normal', 'benign') ###combining variables
label(heart) = 'Heart Disease Code'
map = (2*dbp+sbp)/3
label(map) = 'Mean Arterial Pressure/10' ##comnining vairables
dd = datadist(dd, heart, map) # add combined variables to datadist(dd)
################################################################################
## Compare reduced models with survival model and compare AIC with full model ##
################################################################################
# new model
f2 = cph(S ~ rx + rcs(age,3) + rcs(wt, 3) + pf.coded + heart + rcs(map,3) +
rcs(hg, 4) + rcs(sg, 3) + rcs(sz, 3) + rcs(log(ap), 5) + bm,
x = TRUE, y = TRUE, surv = TRUE, time.inc = 5*12)
anova(f2)
f2
anova(f2)
z = predict(f2, type = 'terms')
z
z = predict(f2, type = 'terms')
f.short = cph(S ~ z, x = TRUE, y= TRUE)
## Compute shoenfields residuals for each variable
# test the proportional hazard assumption using the cox.zph() function
phtest = cox.zph(f.short, transform = 'identity')
phtest
plot(phtest, var = 'rx')
## Compute shoenfields residuals for each variable
# test the proportional hazard assumption using the cox.zph() function
phtest = cox.zph(f.short, transform = 'identity')
phtest
plot(phtest, var = 'rx')
##* To make it work, the phtest variable should be defined with:
phtest = cox.zph(f.short, transform = 'identity',terms=FALSE)
plot(phtest, var = 'rx')
abline(h=0, col = 2)
phtest
plot(phtest, var = 'wt')
abline(h=0, col = 2)
f.short
abline(h=1, col = 2)
plot(phtest, var = 'bm')
abline(h= 0.9988, col = 2)
z.dose = z[, 1]  # z[,1] get column rx (dose)
z.other = z[, -1] #all other columns
## compare model
#
f.ia = cph(S ~ z.dose * z.other)
options(prType='latex') # options(prType='plain') to restore the default
latex(anova(f2), file='', label = 'tab:coxcase-anova1')
options(prType='plain') # options(prType='plain') to restore the default
latex(anova(f2), file='', label = 'tab:coxcase-anova1')
latex(anova(f2), file='', label = 'tab:coxcase-anova1')
f.ia
ggplot(predict(f2), sepdiscrete='vertical', nlevels=4, vnames='names')
#
ggplot(Predict(f2), sepdiscrete='vertical', nlevels=4, vnames='names')
set.seed(1)
v = validate(f2, B=300)
latex(v, file = '')
print(v)
v
cal = calibrate(f2, B=300, u=5*12, maxdim = 4)
plot(cal, subtitles = FALSE)
cal = calibrate(f2, B=300, u=10, maxdim = 4)
plot(cal, subtitles = FALSE)
cal = calibrate(f2, B=300, u=30, maxdim = 4)
plot(cal, subtitles = FALSE)
cal = calibrate(f2, B=300, u=100, maxdim = 4)
cal = calibrate(f2, B=300, u=100, maxdim = 4)
cal = calibrate(f2, B=300, u=70, maxdim = 4)
f2
update(f2, time.inc = 30)
cal = calibrate(f2, B=300, u=30, maxdim = 4)
update(f2, time.inc = 30)
cal = calibrate(f2, B=300, u=30, maxdim = 4)
f2 = update(f2, time.inc = 30)
cal = calibrate(f2, B=300, u=30, maxdim = 4)
plot(cal, subtitles = FALSE)
cal = calibrate(f2, cmethod = 'KM', u = 30, B = 120)
plot(cal, add = TRUE)
plot(summary(f2, ap=c(1,20)), log=TRUE, main = '')
table(status)
table(rx)
table(rx, status != 'alive', na.rm=TRUE)
table(rx, prostate$status != 'alive', na.rm=TRUE)
require(rms)
require(tidyverse)
##################
#import test data#
##################
getHdata(prostate)
#combine two levels in EKG column
levels(prostate$ekg)[levels(prostate$ekg) %in% c('old MI', 'recent MI')] = 'MI'
#new column that converts pf data into intger values (1 to 4)
prostate$pf.coded = as.integer(prostate$pf)
# Merge last two levels (levels 3 and 4 as 3)
levels(prostate$pf.coded) = c(levels(prostate$pf.coded)[1:3], levels(prostate$pf.coded)[3])
#################################
# make prostate data set global #
#################################
attach(prostate)
describe(prostate)
# deaths
table(status)
# deaths caused by prostate
table(status %in% 'dead - prostatic ca')
table(status == 'dead - prostatic ca')
# Determine missing data
prostate %>%
filter(if_any(everything(), is.na)) # 27 rows with missing data
# impute missing data
w = transcan(~ sz + sg + ap + sbp + dbp + age + wt + hg + ekg + pf + bm + hx,
imputed = TRUE, trantab=TRUE, data = prostate, pl = FALSE, pr = FALSE)
# explore reliabilty of imputed values
summary(w)
# Create variable for imputed values
sz = impute(w, sz, data = prostate)
sg = impute(w, sg, data = prostate)
age = impute(w, age, data = prostate)
wt = impute(w, wt, data = prostate)
ekg = impute(w, ekg, data = prostate)
#  bind data to datadist object, this is a utility function to direct functions from to this data object
dd = datadist(prostate); options(datadist = 'dd')
units(dtime) = 'Month'
dd
S = Surv(dtime, status == 'dead - prostatic ca' )
km = npsurv(S ~ rx, type='fleming')
survplot(km, conf = 'bands',
label.curves = list(keys='lines'),
levels.only = TRUE)
# Is there a significant difference? - logrank test
survdiff(S~rx)
events = sum(status %in% 'dead - prostatic ca')
parameters = events/15
# Number of parameters
ncol(select(prostate, everything(), -patno, -status, -pf))
heart = hx + ekg %nin% c('normal', 'benign') ###combining variables
label(heart) = 'Heart Disease Code'
map = (2*dbp+sbp)/3
label(map) = 'Mean Arterial Pressure/10' ##comnining vairables
dd = datadist(dd, heart, map) # add combined variables to datadist(dd)
f = cph(S ~ rx + rcs(age,3) + wt + map + pf.coded + hg + sz + ap + bm,
x = TRUE, y = TRUE, surv = TRUE, time.inc = 5*12)
anova(f)
# model over fitting ?
####*** This is stored in f$stats[4]
df = f$stats[4] #degree of freedom
####*** This is stored in f$stats[3]
LR = f$stats[3] #liklihood ratio
shrinkage = (LR-df)/LR
(1-shrinkage)*100 # estimated percentage of fitted noise
AIC = LR-2*df
print(AIC)
####**** The effect of treatment now seems to make sense
####*with at least 1mg of estrogen having some effect
ggplot(Predict(f), sepdiscrete='vertical', nlevels=4, vnames='names')
##############################
# interactions with dosage ? #
##############################
# predict values based on model
z =  predict(f, type = 'terms')
# predicted dosage
z.dosage = z[,1]
z.other = z[,-1]
f.ia= cph(S~z.dosage*z.other, x=TRUE, y=TRUE)
print(f.ia)
anova(f.ia)
###*** NOTE: this should be 'Schoenfeld'
###*
plot(phtest, var = 'rx', main = 'Shoenfelds residual plot - rx') +
abline(h = 1, col = 2, lty = 2)
z = predict(f, type = 'terms')
f.short = cph(S ~ z, x = TRUE, y= TRUE)
phtest = cox.zph(f.short, transform = 'identity', terms = FALSE)
phtest
par(mfrow=c(3,3),
oma = c(2,2,2,2) + 0.1,
mar = c(2,2,2,2) + 0.1)
###*** NOTE: this should be 'Schoenfeld'
###*
plot(phtest, var = 'rx', main = 'Shoenfelds residual plot - rx') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'age', main = 'Shoenfelds residual plot - age') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'wt', main = 'Shoenfelds residual plot - wt') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'map', main = 'Shoenfelds residual plot - map') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'pf.coded', main = 'Shoenfelds residual plot - pf.coded') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'hg', main = 'Shoenfelds residual plot - hg') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'sz', main = 'Shoenfelds residual plot - sz') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'ap', main = 'Shoenfelds residual plot - ap') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'bm', main = 'Shoenfelds residual plot - bm') +
abline(h = 1, col = 2, lty = 2)
summary(phtest)
f.short
#############
#* 1) I haven't checked the assumption that data is linear
####*** The model you fitted assumed nonlinearity of age (as a continuous predictor) and rx
####*(encoded as a multilevel factor). Ideally, as we discussed for the logistic model applied to
####*the calorimetric data, we would want to use Spearman's rho squared to assess the strength of association
####*between each predictor and the outcome in a nonparametric way, so that it might be worth
####*"expending" degrees of freedom (i.e. using nonlinearities) for predictors with strong associations with
####*the outcome. However, due to censoring, Spearman's rho squared statistic cannot be used.
####*What we can do, however, is use Somers' Dxy rank correlation in the same way.
####*See Harrell's book, p.461 for more details. In this case, we could use something like:
sDxy = rcorrcens(S ~ rx + age + wt + map + pf.coded + hg + sz + ap + bm)
plot(sDxy, main='')
par(mfrow=c(1,1))
#############
#* 1) I haven't checked the assumption that data is linear
####*** The model you fitted assumed nonlinearity of age (as a continuous predictor) and rx
####*(encoded as a multilevel factor). Ideally, as we discussed for the logistic model applied to
####*the calorimetric data, we would want to use Spearman's rho squared to assess the strength of association
####*between each predictor and the outcome in a nonparametric way, so that it might be worth
####*"expending" degrees of freedom (i.e. using nonlinearities) for predictors with strong associations with
####*the outcome. However, due to censoring, Spearman's rho squared statistic cannot be used.
####*What we can do, however, is use Somers' Dxy rank correlation in the same way.
####*See Harrell's book, p.461 for more details. In this case, we could use something like:
sDxy = rcorrcens(S ~ rx + age + wt + map + pf.coded + hg + sz + ap + bm)
plot(sDxy, main='')
##################
#import test data#
##################
getHdata(prostate)
#combine two levels in EKG column
levels(prostate$ekg)[levels(prostate$ekg) %in% c('old MI', 'recent MI')] = 'MI'
#new column that converts pf data into intger values (1 to 4)
prostate$pf.coded = as.integer(prostate$pf)
# Merge last two levels (levels 3 and 4 as 3)
levels(prostate$pf.coded) = c(levels(prostate$pf.coded)[1:3], levels(prostate$pf.coded)[3])
#################################
# make prostate data set global #
#################################
attach(prostate)
describe(prostate)
# deaths
table(status)
# deaths caused by prostate
table(status %in% 'dead - prostatic ca')
table(status == 'dead - prostatic ca')
# Determine missing data
prostate %>%
filter(if_any(everything(), is.na)) # 27 rows with missing data
# impute missing data
w = transcan(~ sz + sg + ap + sbp + dbp + age + wt + hg + ekg + pf + bm + hx,
imputed = TRUE, trantab=TRUE, data = prostate, pl = FALSE, pr = FALSE)
# explore reliabilty of imputed values
summary(w)
# Create variable for imputed values
sz = impute(w, sz, data = prostate)
sg = impute(w, sg, data = prostate)
age = impute(w, age, data = prostate)
wt = impute(w, wt, data = prostate)
ekg = impute(w, ekg, data = prostate)
#  bind data to datadist object, this is a utility function to direct functions from to this data object
dd = datadist(prostate); options(datadist = 'dd')
units(dtime) = 'Month'
dd
#  bind data to datadist object, this is a utility function to direct functions from to this data object
dd = datadist(prostate); options(datadist = 'dd')
units(dtime) = 'Month'
dd
S = Surv(dtime, status == 'dead - prostatic ca' )
km = npsurv(S ~ rx, type='fleming')
survplot(km, conf = 'bands',
label.curves = list(keys='lines'),
levels.only = TRUE)
# Is there a significant difference? - logrank test
survdiff(S~rx)
events = sum(status %in% 'dead - prostatic ca')
parameters = events/15
paramaters
parameters
heart = hx + ekg %nin% c('normal', 'benign') ###combining variables
label(heart) = 'Heart Disease Code'
map = (2*dbp+sbp)/3
label(map) = 'Mean Arterial Pressure/10' ##comnining vairables
dd = datadist(dd, heart, map) # add combined variables to datadist(dd)
#############
#* 1) I haven't checked the assumption that data is linear
####*** The model you fitted assumed nonlinearity of age (as a continuous predictor) and rx
####*(encoded as a multilevel factor). Ideally, as we discussed for the logistic model applied to
####*the calorimetric data, we would want to use Spearman's rho squared to assess the strength of association
####*between each predictor and the outcome in a nonparametric way, so that it might be worth
####*"expending" degrees of freedom (i.e. using nonlinearities) for predictors with strong associations with
####*the outcome. However, due to censoring, Spearman's rho squared statistic cannot be used.
####*What we can do, however, is use Somers' Dxy rank correlation in the same way.
####*See Harrell's book, p.461 for more details. In this case, we could use something like:
sDxy = rcorrcens(S ~ rx + age + wt + map + pf.coded + hg + sz + ap + bm)
plot(sDxy, main='')
f = cph(S ~ rx + age + wt + map + pf.coded + hg + sz + rcs(ap, 3) + bm,
x = TRUE, y = TRUE, surv = TRUE, time.inc = 5*12)
anova(f)
# model over fitting ?
####*** This is stored in f$stats[4]
df = f$stats[4] #degree of freedom
####*** This is stored in f$stats[3]
LR = f$stats[3] #liklihood ratio
shrinkage = (LR-df)/LR
(1-shrinkage)*100 # estimated percentage of fitted noise
####**** The effect of treatment now seems to make sense
####*with at least 1mg of estrogen having some effect
ggplot(Predict(f), sepdiscrete='vertical', nlevels=4, vnames='names')
##############################
# interactions with dosage ? #
##############################
# predict values based on model
z =  predict(f, type = 'terms')
# predicted dosage
z.dosage = z[,1]
z.other = z[,-1]
f.ia= cph(S~z.dosage*z.other, x=TRUE, y=TRUE)
print(f.ia)
anova(f.ia)
z = predict(f, type = 'terms')
f.short = cph(S ~ z, x = TRUE, y= TRUE)
phtest = cox.zph(f.short, transform = 'identity', terms = FALSE)
phtest
phtest = cox.zph(f.short, terms = FALSE)
phtest
phtest = cox.zph(f.short, transform = 'identity', terms = FALSE)
par(mfrow=c(3,3),
oma = c(2,2,2,2) + 0.1,
mar = c(2,2,2,2) + 0.1)
###*** NOTE: this should be 'Schoenfeld'
###*
plot(phtest, var = 'rx', main = 'Shoenfelds residual plot - rx') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'age', main = 'Shoenfelds residual plot - age') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'wt', main = 'Shoenfelds residual plot - wt') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'map', main = 'Shoenfelds residual plot - map') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'pf.coded', main = 'Shoenfelds residual plot - pf.coded') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'hg', main = 'Shoenfelds residual plot - hg') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'sz', main = 'Shoenfelds residual plot - sz') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'ap', main = 'Shoenfelds residual plot - ap') +
abline(h = 1, col = 2, lty = 2)
plot(phtest, var = 'bm', main = 'Shoenfelds residual plot - bm') +
abline(h = 1, col = 2, lty = 2)
phtest
f.short
par(mfrow=c(1,1))
# set seed generates a predictable set of random numbers for repeatable results
set.seed(1)
# Validating the f2 model using bootstrapping of 300
####*** NOTE: you might want to use a larger bootstrap sample, say 1000
####*this may be crucial with small sample sizes.
v = validate(f, B=1000)
# Validating the f2 model using bootstrapping of 300
####*** NOTE: you might want to use a larger bootstrap sample, say 1000
####*this may be crucial with small sample sizes.
f = update(f, time.inc = 60)
# Validating the f2 model using bootstrapping of 300
####*** NOTE: you might want to use a larger bootstrap sample, say 1000
####*this may be crucial with small sample sizes.
f = update(f, time.inc = 60)
v = validate(f, u=60, B=1000)
print(v)
####*** this is stored in v[1,5]
Dxy = v[1,5]
c.index = Dxy*0.5+0.5
print(c.index)
#* Concordance index equals 0.75. meaning that the model correctly ranks the
#* predicted outcome to observed. Ideally this would want to be > 0.8.
####**** NOTE: this model is much better than the original one; correctly ranking 3/4
####*of the patients is considered acceptable by many clinicians
####*
shrinkage = v[3,5]
print(shrinkage)
shrinkage
# set random seed
set.seed(1)
# set time interval where survival will be measured against, Note this was set before but for clarity we are reinstating this at 60 months (5years)
f = update(f, time.inc = 60)
# calibrate data set using bootstrap of 300 permutations (b), point in time to calibrate model 60 months (u) – this needs to be the same as time.inc, maximum dimensions (m) – not sure if this is number of predictors used?
####**** NOTE: maxdim gives the maximum complexity of the smoother used to obtain the calibration graph
cal = calibrate(f, B=1000, u=60, maxdim = 4)
####*** NOTE: I am getting an error in the plot command, my R doesn't like the + syntax apparently?
####*
plot(cal, subtitles = FALSE)
legend(0.55,0.2, legend = c('expected', 'observed'), col=c("black", "blue"), lty = 1, cex=0.8)
#add lines to plot to visualise over estimation of survival
abline(h=0.5, col="grey", lty = 2, cex = 1.5)
abline(v=0.5, col = 'grey', lty = 2, cex = 0.5)
###*** NOTE: you must reset the seed to the same one you used earlier, and with the same
###*number of bootstrap samples
set.seed(1)
cal = calibrate(f, cmethod = 'KM', u = 5*12, B = 1000)
plot(cal, add = TRUE)
### calibrate at 30 months ###
# set random seed
set.seed(1)
# set time interval where survival will be measured against, Note this was set before but for clarity we are reinstating this at 60 months (5years)
f = update(f, time.inc = 30)
# calibrate data set using bootstrap of 300 permutations (b), point in time to calibrate model 60 months (u) – this needs to be the same as time.inc, maximum dimensions (m) – not sure if this is number of predictors used?
cal = calibrate(f, B=1000, u=30, maxdim = 4)
# Plot results
plot(cal, subtitles = FALSE) +
legend(0.5,0.3, legend = c('expected', 'observed'), col=c("black", "blue"), lty = 1, cex=0.8)
# set time interval where survival will be measured against, Note this was set before but for clarity we are reinstating this at 60 months (5years)
f = update(f, time.inc = 90)
# calibrate data set using bootstrap of 300 permutations (b), point in time to calibrate model 60 months (u) – this needs to be the same as time.inc, maximum dimensions (m) – not sure if this is number of predictors used?
cal = calibrate(f, B=1000, u=90, maxdim = 4)
### calibrate at 30 months ###
# set random seed
set.seed(1)
# set time interval where survival will be measured against, Note this was set before but for clarity we are reinstating this at 60 months (5years)
f = update(f, time.inc = 90)
# calibrate data set using bootstrap of 300 permutations (b), point in time to calibrate model 60 months (u) – this needs to be the same as time.inc, maximum dimensions (m) – not sure if this is number of predictors used?
cal = calibrate(f, B=1000, u=90, maxdim = 4)
# set time interval where survival will be measured against, Note this was set before but for clarity we are reinstating this at 60 months (5years)
f = update(f, time.inc = 45)
# calibrate data set using bootstrap of 300 permutations (b), point in time to calibrate model 60 months (u) – this needs to be the same as time.inc, maximum dimensions (m) – not sure if this is number of predictors used?
cal = calibrate(f, B=1000, u=90, maxdim = 4)
# calibrate data set using bootstrap of 300 permutations (b), point in time to calibrate model 60 months (u) – this needs to be the same as time.inc, maximum dimensions (m) – not sure if this is number of predictors used?
cal = calibrate(f, B=1000, u=45, maxdim = 4)
# Plot results
plot(cal, subtitles = FALSE) +
legend(0.5,0.3, legend = c('expected', 'observed'), col=c("black", "blue"), lty = 1, cex=0.8)
#add lines to plot to visualise over estimation of survival
abline(h=0.5, col="grey", lty = 2, cex = 1.5)
abline(v=0.45, col = 'grey', lty = 2, cex = 0.5)
abline(v=0.5, col = 'grey', lty = 2, cex = 0.5)
###*** NOTE: you should have used u=30 if you wanted to compare with the previous smoothed calibration
###*Also, B=50 is way too small and should be equal to the previous, and the seed should be equal, too
# set random seed
set.seed(1)
cal = calibrate(f, cmethod = 'KM', u = 30, B = 1000)
cal = calibrate(f, cmethod = 'KM', u = 45, B = 1000)
plot(cal, add = TRUE)
####################
# summarising data #
####################
plot(summary(f))
f.small = predict(f, type= 'lp')
f.small
#############
#* 1) I haven't checked the assumption that data is linear
####*** The model you fitted assumed nonlinearity of age (as a continuous predictor) and rx
####*(encoded as a multilevel factor). Ideally, as we discussed for the logistic model applied to
####*the calorimetric data, we would want to use Spearman's rho squared to assess the strength of association
####*between each predictor and the outcome in a nonparametric way, so that it might be worth
####*"expending" degrees of freedom (i.e. using nonlinearities) for predictors with strong associations with
####*the outcome. However, due to censoring, Spearman's rho squared statistic cannot be used.
####*What we can do, however, is use Somers' Dxy rank correlation in the same way.
####*See Harrell's book, p.461 for more details. In this case, we could use something like:
sDxy = rcorrcens(S ~ rx + age + wt + map + pf.coded + hg + sz + ap + bm)
plot(sDxy, main='')
anova(f)
f.reduce = ols(f.small ~ rx + age +map + pf.coded, sigma = 1)
f.reduced
f.reduce
anova(f, f.reduced)
anova(f.reduced)
anova(f.reduce)
x = predict(f.reduce)
ggplot(x, f.small)
plot(x, f.small)
f.reduce = ols(f.small ~ rx + age +map + pf.coded, ap, sigma = 1)
f.reduce = ols(f.small ~ rx + age +map + pf.coded + rcs(ap,3), sigma = 1)
f.reduce
anova(f.reduce)
x = predict(f.reduce)
plot(x, f.small)
spearman2(f.small~x)
spearman2(f.small~x, p=2)
